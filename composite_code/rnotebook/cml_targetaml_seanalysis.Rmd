---
title: "Discovery of Acute Myeloid Leukemia Biomarkers using Ensemble Machine Learning"
output: html_notebook
---

```{r setup, include=FALSE}
require(knitr)
# knitr::opts_knit$set(root.dir = '~/Documents/GitHub/RNAseq_Cancer_Biomarkers/')
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=50),
                      tidy=TRUE, 
                      fig.align='center', 
                      fig.height=5, 
                      fig.width=8, 
                      dpi = 600,
                      echo=FALSE,
                      eval=TRUE)
options(stringsAsFactors = FALSE)
```

```{r libraries, eval=TRUE, echo=FALSE}
# dependency libraries
library(plyr)
library(mlr)
library(magrittr)
library(ggplot2)
library(EnsDb.Hsapiens.v75)
library(glmnet)
library(ROSE)
library(knitr)
library(stringr)
library(dplyr)
library(tibble)
library(tidyr)
library(limma)
library(edgeR)
library(MLSeq)
library(DESeq2)
library(xlsx)
library(VennDiagram)
library(SummarizedExperiment)
library(GenomicRanges)
library(circlize)
library(reshape2)

```

```{r mlfunctions, eval=FALSE}
# ML functions

# Lasso
glm.binom <- function(x, y, df, ref="No", train.names=NULL, test.names=NULL, 
                      standardize=FALSE, splitIntoTrain=FALSE){
  # credit: Jenny Smith
  library(glmnet)
  #df is the matrix with the response and  gene expression. Patients as rownames.
  #x is the character vector of column names for genes 
  #y is the character vector of column names for the classifier 
  #train is a chacter vector of patient IDs
  #test is a chacter vector of Patient IDs. 
  
  response <- y
  predictors <- x
  
  #check this that referece should be the first level in glmnet package
  #Set-up the x and y matrices 
  y <- factor(df[,y])
  y <- relevel(y,ref = ref)  %>% set_names(rownames(df))
  x <- as.matrix(df[,x]) #NOTE: for categorical predictors data, should use model.matrix 
  
  
  if (any(c(is.na(y), is.na(x)))) {
    print("There Are Missing Values.")
    return(list(x=x,y=y))
  }
  
  #Check the reference level of the response.
  contrast <- contrasts(y)

  if(splitIntoTrain){
    #Use validation set approach. split observations into approx. equal groups.
    set.seed(1)  
    train <- sample(c(TRUE,FALSE), nrow(x), replace = TRUE)
    test <- (!train)
  
    train.names <- rownames(df)[train]
    test.names <- rownames(df)[test]
  }


  #grid of lambda values to test.
  grid <- 10^ seq(10,-2, length=100)
    
  #training model.
  fit <- glmnet(x[train.names,], y[train.names],
                family = "binomial",
                alpha=1,
                standardize = standardize, 
                lambda = grid, 
                intercept = FALSE)

  #use cross-validation on the training model.CV only for lambda
  set.seed(2019) 
  cv.fit <- cv.glmnet(x[train.names,], y[train.names],
                  family = "binomial",
                  type.logistic="modified.Newton", 
                  standardize = standardize,
                  lambda = grid,
                  alpha=1,
                  nfolds = length(train.names), #LOOCV 
                  type.measure = "class", 
                  intercept = FALSE)

  #Select lambda min.
  lambda.min <- cv.fit$lambda.min

  #predict the classes
  pred.class <- predict(fit, newx = x[test.names,], type="class", s=lambda.min)

  #find the test error
  tab <- table(pred.class,y[test.names])
  testError <- mean(pred.class != y[test.names]) #how many predicted classes were incorrect

  #Fit the full dataset.
  final <- glmnet(x, y,family = "binomial",
                  standardize = standardize, 
                  lambda = grid,
                  alpha = 1,
                  intercept = FALSE)

  #Extract the coefficients
  coef <- predict(final, type="coefficients", s=lambda.min)
  idx <- which(coef != 0)
  nonZero <- coef[idx,]

  #Results 
  list <- list(train.names, test.names, contrast, fit, cv.fit,tab,testError, final, nonZero)
  names(list) <- c("training.set", "testing.set","contrast", "train.fit",
                   "cv.fit", "confusionMatrix","test.error", "final.model", "nonzero.coef")
  return(list)
  
}

# SVM
runSVM <- function(seed,kerneltype="linear",trainset,trainclasses,
                   testset,testclasses, weightfilt=FALSE){
  # credit : Sean Maden
  # run SVM optimization
  # Arguments
  #   * seed : set seed (int) for randomization
  #   * kerneltype : (str) type of kernel for SVM, either 'linear' or 'gaussian'
  #   * trainset : training dataset (excluding sample classes)
  #   * trainclasses : classes for training sampels (vector) with 1:1 correspondence 
  #       with trainset rows
  #   * testset : test data (data frame or matrix), excluding classes
  #   * testclasses : classes for test samples (vector), with 1:1 row:pos correspondence
  #   * weightfilt : (FALSE or numeric) top percentage weights to use in model 
  #       (if FALSE, then all weights used) 
  # Returns
  #   * rl (list) : list containing model fitted, predictions, and performacne metrics
  require(e1071); require(ROCR)
  rl <- list(); str.options <- ""
  set.seed(seed)
  ndtr <- trainset
  ndte <- testset
  ndtr.classes <- trainclasses
  ndte.classes <- testclasses
  
  # train svm model
  svm_model <- svm(as.factor(ndtr.classes)~., 
                   data=ndtr, 
                   method="C-classification", 
                   kernel=kerneltype)
  weightsvect <- ndtr.weights <- t(svm_model$coefs) %*% svm_model$SV
  if(weightfilt){
    str.options <- c(str.options,paste0("weight filt = ",weightfilt))
    # order training data on relative weights
    ndtr.weightsort <- ndtr[,rev(order(abs(ndtr.weights)))]
    # select only top proportion weights
    nweight.col = round(ncol(ndtr.weightsort)*weightfilt,0)
    ndtr.weightfilt <- ndtr.weightsort[,c(1:nweight.col)]
    str.options <- c(str.options,paste("cols_retained:",colnames(ndtr.weightfilt),collapse=";"))
    # redefine training set, rerun SVM optimization
    ndtr <- ndtr.weightfilt
    svm_model <- svm(as.factor(ndtr.classes)~., 
                     data=ndtr, 
                     method="C-classification", 
                     kernel=kerneltype)
  } else{
    str.options <- c(str.options,"no weight filt")
  }
  pred_train <- predict(svm_model, ndtr, decision.values = TRUE)
  pred_test <- predict(svm_model, ndte, decision.values = TRUE)
  # get performance metrics
  pred <- prediction(as.numeric(attr(pred_test,"decision.values")),ndte.classes)
  perf <- performance(pred,"tpr","fpr")
  ppred <- pred_test[pred_test==1]; 
  tppred <- ndte.classes[pred_test==1]
  ppred <- as.numeric(as.character(ppred))
  testprec <- length(ppred[ppred==tppred])/length(ppred) # test precision
  rposi <- ndte.classes==1
  rtpred <- ndte.classes[rposi]; 
  rppred <- pred_test[rposi]
  rppred <- as.numeric(as.character(rppred))
  testrec <- length(rppred[rppred==1])/length(rppred) # test recall
  
  # return model, pred's, and performance metrics
  rl <- list(str.options,
             svm_model,
             weightsvect,
             pred_train,
             pred_test,
             perf,
             tppred,
             testprec,
             testrec)
  names(rl) <- c("options_string",
                 "svm_model",
                 "weightsvect",
                 "predictions_train",
                 "predictions_test",
                 "performance_test",
                 "TPR_test",
                 "precision_test",
                 "recall_test"
  )
  return(rl)
  
}

```

```{r utilityfunctions, eval=FALSE}
# utilities for data summaries and visualization

# differential gene expression
voom_DE <- function(counts.df, ref, pheno){
  # credit: Jenny Smith
  #counts.df is a dataframe with count data, with genes as rownames
  #pheno is a character vector with patient IDs as names, and the status for each in each group(eg pos,neg)
  require(edgeR)
  library(limma)
  
  #ensure correct order for both expn and counts.df
  samples <- intersect(names(pheno), colnames(counts.df))
  pheno <- pheno[samples]
  counts.df <- counts.df[,samples]
  
  
  groups <- unique(pheno)
  groups <- c(groups[groups != ref], ref) #order so that reference is second 
  pheno.f <- factor(pheno, levels=groups)

  dge <- DGEList(counts = counts.df, group = pheno.f)

  keep.dge <- rowSums(cpm(dge) >= 1) > (0.05*ncol(counts.df)) #5% of samples with CPM >= 1
  dge <- dge[keep.dge,]
  dge <- calcNormFactors(dge)

  design <- model.matrix(~0 + pheno.f, data=dge$samples)
  colnames(design) <- levels(pheno.f)
  cont.matrix <- makeContrasts(contrasts = paste(groups, collapse = "-"), levels = design)
  
  
  v.lv <- voom(dge, design, plot = FALSE)
  

  fit <- lmFit(v.lv, design)
  fit <- contrasts.fit(fit, contrasts = cont.matrix)
  fit <- eBayes(fit)
  table <- topTable(fit, number = 20000, p.value=0.05, adjust.method="BH", sort.by="P",lfc=1)
  


  list <- list(design, v.lv, fit, table)
  names(list) <- c("desingMatrix", "voomTransformation", "fit", "DEGs")
  return(list)
}

# Survival by sample groups, plot summaries
{
  # credit: Sean Maden
  ggdat <- as.data.frame(matrix(ncol=2,nrow=0))
ggdat <- rbind(ggdat,data.frame(group='young.overallsurv',survival.time=aml.cd[class.age=='young',]$Overall.Survival.Time.in.Days))
ggdat <- rbind(ggdat,data.frame(group='young.efsurv',survival.time=aml.cd[class.age=='young',]$Event.Free.Survival.Time.in.Days))
ggdat <- rbind(ggdat,data.frame(group='old.overallsurv',survival.time=aml.cd[class.age=='old',]$Overall.Survival.Time.in.Days))
ggdat <- rbind(ggdat,data.frame(group='old.efsurv',survival.time=aml.cd[class.age=='old',]$Event.Free.Survival.Time.in.Days))

ggplot(ggdat, aes(x=ggdat$survival.time, col=ggdat$group))+geom_density()+
  theme(panel.background = element_rect(fill = 'white',colour = 'black'),
        rect = element_rect(fill = 'white',colour = "white"),
        panel.grid.major = element_line(colour = 'grey75', size=0.2),
        panel.grid.minor = element_line(colour = 'white'),
        legend.position = 'right',
        legend.background = element_rect(fill = "white", 
                                         colour ="white"),
        legend.key = element_rect(fill = "white"),
        plot.title = element_text(hjust = 0.5))+
  labs(color="Group Survival") + 
  ggtitle("Survival Time by Age Classifier")
}

# Categorize DEGs
catExpnData <- function(filenames,regex, cols, header=FALSE,removeFirstLine=FALSE, sep="\t"){
  #credit: Jenny Smith
  # Purpose: Concatenate the expression data-sets downloaded from TCGA/TARGET from GDC or any patient level data
  #eg. each individual patient has a single expression-file 
  
  library(magrittr)
  options(stringsAsFactors = FALSE)
  #filenames is a character vector of all filenames. 
  #regex is a string with the pattern to extract the patient ID , eg "^.+(Kasumi|MV4)", from filenames 
  #cols is the character vector or numeric vector of the columns to select and concatenate. 
  
  extract_cols <-function(filename,cols,rmFirstLine=FALSE){
    
    if(all(rmFirstLine & header)){
      aFile <- readLines(filename)[-1] #remove first line with extra info. 
      aFile <- str_split_fixed(aFile, pattern = "\t",n = length(cols)) %>% #split into a matrix
        set_colnames(.[1,] ) %>%  #set colnames from the first line 
        .[-1, ] #remove the header row from matrix
    }else{
      aFile <- read.delim(filename, sep=sep, header=header, as.is=TRUE)
    }
    
    output <- list()
    for ( k in 1:length(cols)){
      colname <- cols[k]
      col <- aFile[,colname]
      output[[colname]] <- col
    }
    return(output)
  }
  
  combineColumns <- function(extract_cols.res,colname){
    sapply(extract_cols.res, '[[', colname)
  }
  
  
  IDs <- gsub(regex, "\\1", filenames)
  
  columns <- lapply(filenames,extract_cols,cols=cols, rmFirstLine=removeFirstLine) %>%
    set_names(IDs)
  
  catedMatrices <- lapply(cols, combineColumns, extract_cols.res=columns)  %>%
    set_names(cols)
  
  
  return(catedMatrices)
}

# Gene summary scatter plots
{
  # credit: Sean Maden
  jpeg("target-aml_gene-meanvar-diff_test-train.jpg",10,15,units="in",res=400)
par(mfrow=c(2,1))
col.deg <- rgb(0.2,0.5,0.2,0.3)
col.all <- rgb(0.7,0.1,0.2,0.3)
test.na <- is.na(test.degdiff) | is.na(test.degvar)
plot(test.degdiff[!test.na], test.degvar[!test.na], pch=16, col=col.deg,
     main = "TARGET AML Test Subset",xlab="Gene mean diff (Low - Not-low)", ylab="Gene var diff (Low - Not-low)")
test.na <- is.na(test.alldiff) | is.na(test.allvar)
points(test.alldiff[!test.na], test.allvar[!test.na], pch=1, col=col.all)
abline(h=0,col="blue");abline(v=0,col="blue")
legend("topright",legend=c("All Genes","DEGs"),pch=c(1,16),col=c(col.all, col.deg))
train.na <- is.na(train.degdiff) | is.na(train.degvar)
plot(train.degdiff[!train.na], train.degvar[!train.na], pch=16, col=col.deg,
     main = "TARGET AML Train Subset",xlab="Gene mean diff (Low - Not-low)", ylab="Gene var diff (Low - Not-low)")
train.na <- is.na(train.alldiff) | is.na(train.allvar)
points(train.alldiff[!train.na], train.allvar[!train.na], pch=1, col=col.all)
abline(h=0,col="blue");abline(v=0,col="blue")
dev.off()
}

# Volcano plot
volcano_plot <- function(fit, cut.off=4, label.offset=0.5){
  # credit : Jenny Smith
  df <- data.frame(logFC=fit$coefficients[,1],
                   pValue=fit$p.value[,1],
                   FDR=p.adjust(fit$p.value[,1], method="BH"),
                   MeanExpression=fit$Amean) %>%
      rownames_to_column("Gene") %>%
      mutate(Neg.Log10.P= -log10(pValue),
             DEGs.Groups=case_when(
                  logFC > 1.0 & pValue < 0.05 ~ "FC Greater than 2",
                  logFC < -1.0 & pValue < 0.05 ~ "FC Less than 2",
                  TRUE ~ "Not Significant FC"))

  
  #Select differentially expressed genes to highlight in the plot. 
  ToHighlight <- df[abs(df$logFC) > cut.off & df$FDR < 0.05, "Gene"] 
  idx <- which(abs(df$logFC) > cut.off & df$FDR < 0.05)
  
  vplot <- ggplot(df, aes(x=logFC, y=Neg.Log10.P)) + 
    geom_point(data = filter(df, DEGs.Groups == "Not Significant FC"), 
               mapping = aes(x=logFC, y=Neg.Log10.P, color=DEGs.Groups), alpha=0.65)  +
    
    geom_point(data= filter(df, grepl("2", DEGs.Groups)), 
               mapping = aes(x=logFC, y=Neg.Log10.P, color=DEGs.Groups)) +
    
    geom_vline(xintercept=c(-1,1)) +
    geom_hline(yintercept = -log10(0.05)) +
    
    scale_color_manual(values=c("FC Greater than 2"="red", 
                                "FC Less than 2"="blue",
                                "Not Significant FC"="lightgrey")) +
    
    theme(plot.title = element_text(hjust = 0.5, size = 20),
          panel.background = element_rect(fill="white"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_rect(color = "black", fill=NA),
          axis.text = element_text(color = "black"),
          axis.text.x = element_text(angle = 0,hjust=0.5,vjust = 0.5, size = 26),
          axis.text.y = element_text(size = 25),
          axis.title = element_text(size = 30),
          plot.margin = margin(2,2,2,2, unit = "mm")) +
    
    geom_text(aes(x=logFC+label.offset, y=Neg.Log10.P, label=ToHighlight),size=3.5,
              data=df[idx, ])
 

  return(vplot)
  
}

```

```{r globals_and_loadobj}
# define globals
sys.sep = "/"
data.dir = "data"
seobj.dir = "seobjects"
figs.dir = "figures"

countsseset.name <- "seset_genecounts_targetaml.rda"
tmmseset.name <- "seset_genetmmfilt_targetaml.rda"
degseset.name <- "seset_degseahack_targetaml.rda"
maeobj.name <- "mae_targetaml.rda"

cormap.tile.name <- "cortest_tile.jpg"
cormap.tri.name <- "cortest_triangle.jpg"
hmdeg.name <- "hmdeg_targetaml.jpg"
hmdeg.rowanno.name <- "hmdeg_rowanno_targetaml.jpg"
hmdeg.traintest.name <- "hmdeg_traintest_targetaml.jpg"

# lasso obj 
smlasso.resultlist.name <- "lasso_resultlist_smtest.rda"
smlasso.resultlist.repname <- "lasso_resultlist_smtest_repnum"
lassocoeff.figure.name <- "lasso_features.jpg"

# rf obj
rf.resultlist.name <- "rfiter-noboost_resultlist_smtest.rda"
rf.plot2k.name <- "rf2k_featureimportance.jpg"
rf.plot5k.name <- "rf5k_featureimportance.jpg"
rf.plot10k.name <- "rf10k_featureimportance.jpg"
rf.plotcomposite.name <- "rfall_noboost_featureimportance.jpg"

# load data 
load(paste0(seobj.dir, sys.sep, degseset.name))

```

# Data Preparation
Summarized Experiment objects were created from TARGET AML clinical and RNA-seq data obtained from GDC. Gene counts from STAR 2-Pass alignment were converted using TMM into log counts-per-million scale. Differentially Expressed Genes were determined comparing classifier sample groups in the training sample subset only. Genes were pre-filered on whether at least 5 samples (set-wide) showing counts per mission greater than or equal to 1. 

# Data Summaries and Pre-filtering Samples with Risk Group Available
```{r summarizeclin, eval=TRUE, echo=TRUE}

# summarise the se object
message("dim se object")
dim(deg.seset)
# [1] 1984  145

message("table of risk group var")
table(deg.seset$Risk.group)
#     High      Low Standard  Unknown 
#       8       60       69        8
deg.seset$deg.risk <- ifelse(deg.seset$Risk.group=="Low", 0,
                             ifelse(deg.seset$Risk.group %in% c("Standard","High"),1,"NA"))
message("table of binarized risk group")
table(deg.seset$deg.risk)
# 0  1 NA 
# 60 77  8
message("table of risk group x binarized risk group")
table(deg.seset$deg.risk, deg.seset$Risk.group)
#       High Low Standard Unknown
#  0     0  60        0       0
#  1     8   0       69       0
#  NA    0   0        0       8

degfilt.se <- deg.seset[,which(deg.seset$deg.risk %in% c(0,1))] # subset on deg risk group available
message("dim of filtered se object")
dim(degfilt.se)
# [1] 1984  137

# summarize gender and age at first diagnosis
message("table of gender x binarized risk")
table(degfilt.se$Gender,degfilt.se$deg.risk)
#           0  1
#   Female 29 40
#   Male   31 37
message("chisq test of gender x binarized risk")
chisq.test(table(degfilt.se$Gender,degfilt.se$deg.risk)) # p-value = 0.8044, gender evenly dist

degfilt.se$binom.age <- ifelse(degfilt.se$Age.at.Diagnosis.in.Days >= median(degfilt.se$Age.at.Diagnosis.in.Days), "old" ,"young")
message("table of binarized age-at-diag x binarized risk")
table(degfilt.se$binom.age,degfilt.se$deg.risk)
#         0  1
#  old   32 37
#  young 28 40
message("chisq results of binarized age-at-diag x binarized risk")
chisq.test(table(degfilt.se$binom.age,degfilt.se$deg.risk)) #  p-value = 0.6591, age evenly dist

```

# Differentially Expressed Genes Summary
```{r summarizedeg, eval=TRUE, echo=TRUE}

allgenes <- rownames(degfilt.se)
genemeans.0 <- rowMeans(assay(degfilt.se[,degfilt.se$deg.risk==0]), na.rm=T)
genemeans.1 <- rowMeans(assay(degfilt.se[,degfilt.se$deg.risk==1]), na.rm=T)
lfc.deg <- log2((genemeans.1/(genemeans.0+0.01)))

message("summary of log2FC")
summary(lfc.deg)
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
# -8.4397 -1.0912 -0.6326 -0.4780  0.4111  7.9643     366

length(allgenes[which(lfc.deg < -4)]) # 27
length(allgenes[which(lfc.deg < -2)]) # 144
length(allgenes[which(lfc.deg < 0)]) # 1165
length(allgenes[which(lfc.deg > 0)]) # 412
length(allgenes[which(lfc.deg > 2)]) # 84
length(allgenes[which(lfc.deg > 4)]) # 14

# plot
plot(density(lfc.deg))
hist(lfc.deg, breaks = 50)
plot(lfc.deg,-1*log10(rowData(degfilt.se)$p.unadj),
     xlab="Log2FC(NotLow_1/Low_0)",
     ylab="-1*log10(padj)")

```

# Heatmap Data Set Summaries
```{r degheatmap, eval=TRUE, echo=FALSE}
require(ComplexHeatmap)
require(circlize)

#=======================
# Heatmap Test vs Train
#=======================
# all data
seset <- degfilt.se
hm_data <- as.matrix(assay(seset))
breaks=seq(min(hm_data),max(hm_data),0.1)
hmcol = colorRamp2(breaks, colorRampPalette(c("green","black","red"))(n=length(breaks)))

# train data
seset <- degfilt.se[,degfilt.se$exptset.seahack=="train"]
hm_data.train <- as.matrix(assay(seset)[!is.na(lfc.deg),])
# hm col annotations can contain complex layered output and colored annotaions
hm_colanno.train <- HeatmapAnnotation(show_legend = TRUE,
                                df = data.frame(sampletype=seset$deg.risk,
                                                gender=seset$Gender,
                                                binom.age=seset$binom.age), 
                                col = list(sampletype = c("0" =  "blue","1" = "red"),
                                           gender = c("Male"="black","Female"="gray"),
                                           binom.age = c("young"="pink","old"="green")),
                                name = "Sample Type",
                                annotation_height = unit(c(0.5, 0.5, 0.5), "cm"))
hm.train <- Heatmap(hm_data.train,
        col=hmcol,
        cluster_columns = TRUE,
        show_heatmap_legend = TRUE,
        top_annotation = hm_colanno.train,
        name="tmm_log_cpm",
        show_row_names = FALSE,
        show_column_names = FALSE,
        column_title = "Train", 
        column_dend_reorder = TRUE,
        row_dend_reorder = TRUE,
        heatmap_legend_param = list(color_bar = "continuous"),
        row_title = "DEGs")

# test data
seset <- degfilt.se[,degfilt.se$exptset.seahack=="test"]
hm_data.test <- as.matrix(assay(seset)[!is.na(lfc.deg),])
# hm col annotations can contain complex layered output and colored annotaions
hm_colanno.test <- HeatmapAnnotation(show_legend = TRUE,
                                df = data.frame(sampletype=seset$deg.risk,
                                                gender=seset$Gender,
                                                binom.age=seset$binom.age), 
                                col = list(sampletype = c("0" =  "blue","1" = "red"),
                                           gender = c("Male"="black","Female"="gray"),
                                           binom.age = c("young"="pink","old"="green")),
                                name = "Sample Type",
                                annotation_height = unit(c(0.5, 0.5, 0.5), "cm"))
hm.test <- Heatmap(hm_data.test,
        col=hmcol,
        cluster_columns = TRUE,
        show_heatmap_legend = TRUE,
        top_annotation = hm_colanno.test,
        name="tmm_log_cpm",
        show_row_names = FALSE,
        show_column_names = FALSE,
        column_title = "Test", 
        column_dend_reorder = TRUE,
        row_dend_reorder = TRUE,
        heatmap_legend_param = list(color_bar = "continuous"),
        row_title = "DEGs")
draw(hm.test+hm.train)

jpeg(paste0(figs.dir, sys.sep, hmdeg.traintest.name), 10, 5, units="in", res=400)
draw(hm.test+hm.train)
dev.off()

#==================
# Heatmap All Data
#==================
# Take normally dist data as heatmap matrix
hm_data <- as.matrix(assay(degfilt.se))
# hm col annotations can contain complex layered output and colored annotaions
hm_colanno <- HeatmapAnnotation(show_legend = TRUE,
                                df = data.frame(sampletype=degfilt.se$deg.risk,
                                                gender=degfilt.se$Gender,
                                                binom.age=degfilt.se$binom.age,
                                                subset=degfilt.se$exptset.seahack), 
                                col = list(sampletype = c("0" =  "blue","1" = "red"),
                                           gender = c("Male"="black","Female"="gray"),
                                           binom.age = c("young"="pink","old"="green"),
                                           subset = c("test" = "orange", "train" = "purple")),
                                name = "Sample Type",
                                annotation_height = unit(c(0.5, 0.5, 0.5, 0.5), "cm"))
breaks=seq(min(hm_data),max(hm_data),0.1)
hmcol = colorRamp2(breaks,colorRampPalette(c("green","black","red"))(n=length(breaks)))
hm <- Heatmap(hm_data,
        col=hmcol,
        cluster_columns = TRUE,
        show_heatmap_legend = TRUE,
        top_annotation = hm_colanno,
        name="log2_tmm_count",
        show_row_names = FALSE,
        show_column_names = FALSE,
        column_title = "Samples", 
        column_dend_reorder = TRUE,
        row_dend_reorder = TRUE,
        heatmap_legend_param = list(color_bar = "continuous"),
        row_title = "DEGs")

#hm

jpeg(paste0(figs.dir, sys.sep, hmdeg.name), 8, 7, units="in", res=400)
hm
dev.off()

# transverse heatmap with log2FC

```

# Machine Learning: Model Fitting and Assessment

```{r standard_table_output}
# make standard table to hold all test results
standtable = as.data.frame(rowData(degfilt.se))

```


```{r svm}
```

```{r lasso}
# Run lasso with glmnet
#df is the matrix with the response and  gene expression. Patients as rownames.
  #x is the character vector of column names for genes 
  #y is the character vector of column names for the classifier 
  #train is a chacter vector of patient IDs
  #test is a chacter vector of Patient IDs. 
#Mod.RG <- glm.binom(x = grep("^ENSG",  colnames(RG.GLM.df), value=TRUE),
#                    y="RiskGroup.Class",
#                    df=RG.GLM.df,
#                    train.names = RG.GLM.df$TARGET.USI[RG.GLM.df$train_test_set=="Train"],
#                    test.names = RG.GLM.df$TARGET.USI[RG.GLM.df$train_test_set=="Test"])

#lasso.fit.rg <- glm.binom(x = gene.names, y = var.classifier, df = glm.df, 
#                          train.names = trainset.names, test.names = testset.names)

#---------------
# SM lasso test
#---------------
repnum = 0
seset <- degfilt.se
dim(seset) # [1] 1937  137

gene.names = as.character(rownames(rowData(seset)))
var.classifier = seset$deg.risk

glm.df = t(assay(seset))
trainset.names = colnames(assay(seset[,seset$exptset.seahack=="train"]))
testset.names = colnames(assay(seset[,seset$exptset.seahack=="test"]))
#----------------------------
df = glm.df 
train.names = trainset.names
test.names = testset.names
#----------------------------
response <- var.classifier
predictors <- gene.names
y <- factor(response); names(y) <- colnames(assay(seset)) # response var obj
x = df[,colnames(df) %in% predictors] # genes of interest
dim(x)
contrast <- contrasts(y)
grid <- 10^ seq(10,-2, length=100)
standardize = FALSE
fit <- glmnet(x[train.names,], y[train.names], family = "binomial", alpha=1, 
              standardize = standardize, lambda = grid, intercept = FALSE)
# use cross-validation on the training model.CV only for lambda
if(repnum==0){
  newseed = 2019
  set.seed(newseed) 
} else{
  newseed = sample(seq(0,10000,1),1)
  set.seed(newseed)
}
cv.fit <- cv.glmnet(x[train.names,], y[train.names], family = "binomial",
                    type.logistic="modified.Newton", standardize = standardize,
                    lambda = grid, alpha=1, nfolds = length(train.names), #LOOCV 
                    type.measure = "class", intercept = FALSE)
#Select lambda min.
lambda.min <- cv.fit$lambda.min
#predict the classes
pred.class <- predict(fit, newx = x[test.names,], type="class", s=lambda.min)
#find the test error
tab <- table(pred.class,y[test.names])
testError <- mean(pred.class != y[test.names]) #how many predicted classes were incorrect
#Fit the full dataset.
final <- glmnet(x, y,family = "binomial", standardize = standardize, 
                lambda = grid, alpha = 1, intercept = FALSE)
#Extract the coefficients
coef <- predict(final, type="coefficients", s=lambda.min)
idx <- which(!as.numeric(coef)==0)
nonZero <- coef[idx,]
#Results 
smlasso.list <- list(train.names, test.names, contrast, fit, 
                     cv.fit, tab, testError, final, nonZero, newseed)
names(smlasso.list) <- c("training.set", "testing.set","contrast", "train.fit",
                 "cv.fit", "confusionMatrix","test.error", "final.model", 
                 "nonzero.coef", "seednum")
if(repnum==0){
  save(smlasso.list, file = paste0(data.dir, sys.sep, smlasso.resultlist.name))
} else{
  save(smlasso.list, file = paste0(data.dir, sys.sep, smlasso.resultlist.repname, repnum, ".rda"))
}

#======================================
# Append Results to Standardized Table
#======================================
coefgenes_dfsym = names(smlasso.list$nonzero.coef)
ncoefgenes_dfsym = rownames(seset[!rownames(seset) %in% coefgenes_dfsym,])

cgl = smlasso.list$nonzero.coef
coeffvect = c(as.numeric(cgl), 
              rep(0, nrow(seset[!rownames(seset) %in% names(cgl)]))
              )
names(coeffvect) <- c(names(cgl), rownames(seset[!rownames(seset) %in% names(cgl)]))
coeffvect = coeffvect[order(match(names(coeffvect), rownames(standtable)))]
identical(names(coeffvect), rownames(standtable))

standtable$lasso_coeff <- coeffvect

#=========================
# Plot lasso coefficients
#=========================
# goi (retained genes with nonzero coeff)
lasso.goi <- names(smlasso.list$nonzero.coef)
# gene symbols
lasso.goi.symbols <- rowData(deg.seset[lasso.goi,])$hgnc_symbol
#data.frame(lasso.goi, lasso.goi.symbols, as.numeric(smlasso.list$nonzero.coef))

# make barplot
bpdat <- smlasso.list$nonzero.coef
gene.order <- order(bpdat)
bpdat <- bpdat[gene.order]
bp.gene.symbols <- paste0(lasso.goi[gene.order],"; ",lasso.goi.symbols[gene.order])
bpcol <- ifelse(bpdat<0,"blue","red")

jpeg(paste0(figs.dir, sys.sep, lassocoeff.figure.name),8,5,units="in",res=400)

par(oma=c(10,2,2,2))
barplot(bpdat, col=bpcol, 
        names.arg = bp.gene.symbols,
        cex.names = 0.6,
        las = 2, 
        ylim = c(-0.1,0.3),
        main = "Lasso Features")
mtext(text="Coefficient",side=2,line=0,outer=TRUE,cex=1)
mtext(text="Gene Symbol",side=1,line=5,outer=TRUE,cex=1)

dev.off()

```

```{r random_forest_noboost}
require(randomForest)

set.seed(20)
train.classes <- ndtr[,1]; train.set <- ndtr[,c(2:ncol(ndtr))]

train.all <- ndtr; 
colnames(train.all) <- c("class",paste0("var",seq(2,ncol(train.all),1)))
train.all$class <- as.factor(train.all$class)

test.all <- ndte; 
colnames(test.all) <- c("class",paste0("var",seq(2,ncol(test.all),1)))
test.all$class <- as.factor(test.all$class)
test.vars <- test.all[,c(2:ncol(test.all))]
# NTrees = 10
rf10 <- randomForest(class ~ .,
                     data=train.all,
                     ntree=10,
                     proximity=TRUE)

# select training data
rfdat.train <- as.data.frame(t(assay(deg.seset[,deg.seset$exptset.seahack=="train"])))
# append binom classes
rfdat.train$class <- as.factor(deg.seset[,deg.seset$exptset.seahack=="train"]$deg.risk)
# form test set as with train set
rfdat.test <- as.data.frame(t(assay(deg.seset[,deg.seset$exptset.seahack=="test"])))
#rfdat.test$class <- as.factor(deg.seset[,deg.seset$exptset.seahack=="test"]$deg.risk)

rf2k <- randomForest(class ~ .,
                     data = rfdat.train,
                     ntree = 2000,
                     proximity = TRUE)

rf5k <- randomForest(class ~ .,
                     data = rfdat.train,
                     ntree = 5000,
                     proximity = TRUE)

rf10k <- randomForest(class ~ .,
                     data = rfdat.train,
                     ntree = 10000,
                     proximity = TRUE)
# assess model fit
pred.rf2k <- predict(rf2k, rfdat.test,'response')
pred.rf5k <- predict(rf5k, rfdat.test,'response')
pred.rf10k <- predict(rf10k, rfdat.test,'response')

table(observed = as.factor(deg.seset[,deg.seset$exptset.seahack=="test"]$deg.risk), 
      predicted = pred.rf2k)
#       predicted
#observed  0  1
#       0 20  2
#       1  1 21
cm.2k <- table(observed = as.factor(deg.seset[,deg.seset$exptset.seahack=="test"]$deg.risk), 
      predicted = pred.rf2k)

table(observed = as.factor(deg.seset[,deg.seset$exptset.seahack=="test"]$deg.risk), 
      predicted = pred.rf5k)
#       predicted
#observed  0  1
#       0 19  3
#       1  1 21
cm.5k <- table(observed = as.factor(deg.seset[,deg.seset$exptset.seahack=="test"]$deg.risk), 
      predicted = pred.rf5k)

table(observed = as.factor(deg.seset[,deg.seset$exptset.seahack=="test"]$deg.risk), 
      predicted = pred.rf10k)
#       predicted
#observed  0  1
#       0 19  3
#       1  1 21
cm.10k <- table(observed = as.factor(deg.seset[,deg.seset$exptset.seahack=="test"]$deg.risk), 
      predicted = pred.rf10k)

rf.returnlist <- list('rf2k.results'=list('fitmodel'=rf2k,'conf.matrix'=cm.2k),
                      'rf5k.results'=list('fitmodel'=rf5k,'conf.matrix'=cm.5k),
                      'rf10k.results'=list('fitmodel'=rf10k,'conf.matrix'=cm.10k))
save(rf.returnlist, file=paste0(data.dir, sys.sep, rf.resultlist.name))

# rf plots


# names(bpi) <- colnames(rfdat.train)[c(2:ncol(rfdat.train))]
# gene symbols

jpeg(paste0(figs.dir, sys.sep, rf.plotcomposite.name),8,10,units="in",res=400)
par(oma=c(5,5,2,1),mfrow=c(3,1))
import.cutoff = 0.2
rfall <- list(rf2k, rf5k, rf10k)
rftitles <- c("2,000 trees", "5,000 trees", "10,000 trees")
for(i in 1:length(rfall)){
  bpi <- as.vector(round(importance(rfall[[i]]), 2))
  names(bpi) <- rowData(deg.seset)$gene.symbol
  bpi <- bpi[order(bpi)]
  bpi <- bpi[bpi>import.cutoff]
  barplot(bpi, las=2, cex.names = 0.7, main=rftitles[i])
  if(i == 2){
    mtext("Importance",side=2,line=4,cex=1)
  }
  if(i == 3){
    mtext(paste0("Top Features (>",import.cutoff," importance)"), side=1, line=7, cex=1)
  }
}
dev.off()

```

```{r random_forest_withboost}
```

```{r automl}
```

# Machine Learning: Checking Correlation with Retained Genes
# Correlational Map
Note: follow up with investigation of repetitions of lasso. Do reps show different predictors retained/eliminated? Are correlated genes correlated because they share pathway/network/annotation with selected predictor?

```{r degcormap, eval=FALSE, echo=FALSE}
# ref: http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization

require(reshape2)
require(ggplot2)

# Corr data, full dataset
cormat <- round(cor(t(assay(degfilt.se)), method="spearman"),3)
melted_cormat <- melt(cormat)
# define cutoffs
qcorcoeff.pos <- quantile(melted_cormat[melted_cormat$value>0,]$value,seq(0,1,0.05))
qcorcoeff.neg <- quantile(melted_cormat[melted_cormat$value<0,]$value,seq(0,1,0.05))
pos.cut <- as.numeric(qcorcoeff.pos[20])
neg.cut <- as.numeric(qcorcoeff.neg[2])

#--------------------------
# cordata from lasso model
#--------------------------
# make nested lists of correlated genes
corlist.lasso <- list()
lasso.goi <- names(smlasso.list$nonzero.coef)
# corgoi.vec <- c(lasso.goi)
for(i in 1:length(lasso.goi)){
  mc.goi <- melted_cormat[melted_cormat$Var1==lasso.goi[i] & 
                            (melted_cormat$value>=pos.cut | 
                               melted_cormat$value<=neg.cut),]
  # append.goi <- unique(mc.goi$Var2)
  # corgoi.vec <- unique(c(corgoi.vec, append.goi))
  # message("new length cargoi.list = ", length(corgoi.vec))
  
  corlist.lasso[[lasso.goi[i]]] <- c(unique(as.character(mc.goi$Var2)))
  
  message(" gene ",lasso.goi[i]," showed n = ",
          length(unique(as.character(mc.goi$Var2))),
          " correlated genes")
}

#-----------------
# cor plots loop
#-----------------
library(reshape2)
library(ggplot2)

  
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
    cormat[upper.tri(cormat)] <- NA
    return(cormat)
  }
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
  }

cplots = list()
for(i in 1:length(corlist.lasso)){
  # form data matrix
  mcplot <- melted_cormat[melted_cormat$Var1==names(corlist.lasso)[i] &
                            melted_cormat$Var2 %in% corlist.lasso[[i]],]
  cormati <- round(cor(t(assay(degfilt.se[unique(c(mcplot$Var1,mcplot$Var2)),])), method="spearman"),3)
  upper_tri <- get_upper_tri(cormati)
  melted_cormat <- melt(upper_tri, na.rm = TRUE)
  
  
  
  # make correlation heatmap
  ggi <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value)) +
          geom_tile(color = "white") +
          scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                         midpoint = 0, limit = c(-1,1), space = "Lab", 
                         name="Spearman\nCorrelation") +
          theme_minimal() + 
          theme(axis.text.x = element_text(angle = 45, vjust = 1, 
          size = 12, hjust = 1)) +
          coord_fixed()
  ggi
  
  cplots <- list(cplots, ggi)
}
  
  # plot and save heatmap
  plotnamei = paste0(figs.dir, sys.sep, "cortriplot_lassocoeff_", gsub("\\..*","",names(corlist.lasso)[i]), ".tiff")
  pdf(plotnamei, 20, 20, units="in", res=400)
  
  dev.off()
  
  message("finished gene ",i)
}

jpeg(paste0(figs.dir, sys.sep, cormap.tile.name), 10, 10, units="in", res=400)
ggplot(data = cormatfilt, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()



#-----------
# tile plot
#-----------
jpeg(paste0(figs.dir, sys.sep, cormap.tile.name), 10, 10, units="in", res=400)
ggplot(data = cormatfilt, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()
dev.off()

#----------------
# triangle plot
#----------------
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
  cormat[upper.tri(cormat)] <- NA
  return(cormat)
  }
  # Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
  }
  
upper_tri <- get_upper_tri(cormat)
upper_tri

# Melt the correlation matrix
library(reshape2)
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Heatmap
library(ggplot2)
ggplot(data = melted_cormat, aes(Var2, Var1, fill = value)) +
 geom_tile(color = "white") +
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") +
  theme_minimal() + 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1)) +
 coord_fixed()

```

# Machine Learning: Predictive Features Consensus

# Results Summaries

# R Env log